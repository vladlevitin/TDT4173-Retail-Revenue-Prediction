{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "stores_train = pd.read_csv('data/stores_train.csv')\n",
    "stores_test = pd.read_csv('data/stores_test.csv')\n",
    "plaace_hierarchy = pd.read_csv('data/plaace_hierarchy.csv')\n",
    "\n",
    "\n",
    "stores_train_copy= stores_train.copy()\n",
    "stores_test_copy= stores_test.copy()\n",
    "\n",
    "plaace_hierarchy_copy = plaace_hierarchy.copy()\n",
    "plaace_hierarchy_copy.drop(columns=['sales_channel_name'], inplace=True)\n",
    "\n",
    "plaace_hierarchy_copy['lv2'] = plaace_hierarchy_copy['lv2'].astype('category')\n",
    "plaace_hierarchy_copy['lv2'] = plaace_hierarchy_copy['lv2'].astype('category')\n",
    "\n",
    "df = stores_train_copy\n",
    "\n",
    "df = pd.merge(df, plaace_hierarchy_copy, how='left', on='plaace_hierarchy_id')\n",
    "\n",
    "busstops = pd.read_csv('data/busstops_norway.csv')\n",
    "busstops_copy = busstops.copy()\n",
    "busstops_copy['busstop_lat'] = busstops_copy['geometry'].apply(lambda x: float(x.split(' ')[1][:-1]))\n",
    "busstops_copy['busstop_lon'] = busstops_copy['geometry'].apply(lambda x: float(x.split(' ')[0][6:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haversine import haversine, Unit\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def find_closest_busstop(lat, lon):\n",
    "    distances = busstops_copy.apply(lambda x: haversine((lat, lon), (x['busstop_lat'], x['busstop_lon']), unit=Unit.METERS), axis=1)\n",
    "    return distances.min()\n",
    "\n",
    "\n",
    "stores_train_copy['closest_busstop'] = stores_train_copy.apply(lambda x: find_closest_busstop(x['lat'], x['lon']), axis=1)\n",
    "stores_test_copy['closest_busstop'] = stores_test_copy.apply(lambda x: find_closest_busstop(x['lat'], x['lon']), axis=1)\n",
    "\n",
    "\n",
    "stores_train_copy.to_csv('data/stores_train_with_busstops.csv', index=False)\n",
    "stores_test_copy.to_csv('data/stores_test_with_busstops.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haversine import haversine, Unit\n",
    "\n",
    "def count_closest_stores(lat, lon, lv2, col, radius):\n",
    "    distances = df[df[col] == lv2].apply(lambda x: haversine((lat, lon), (x['lat'], x['lon']), unit=Unit.METERS), axis=1)\n",
    "    return len(distances[distances < radius] > 0)\n",
    "\n",
    "radius = 500\n",
    "\n",
    "col = 'lv2_desc'\n",
    "\n",
    "df_train['num_closest_stores_lv2'] = df_train.apply(lambda x: count_closest_stores(x['lat'], x['lon'], x['lv2_desc'], col, 500), axis=1)\n",
    "df_test['num_closest_stores_lv2'] = df_test.apply(lambda x: count_closest_stores(x['lat'], x['lon'], x['lv2_desc'], col, 500), axis=1)\n",
    "\n",
    "df_train[['store_id','num_closest_stores_lv2_500m']].to_csv('stores_train_num_closest_stores_lv2_500m.csv', index=False)\n",
    "df_test[['store_id','num_closest_stores_lv2_500m']].to_csv('stores_test_num_closest_stores_lv2_500m.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_total = pd.concat([X, y], axis=1)\n",
    "\n",
    "# X_encoded_target = X_total.copy()\n",
    "\n",
    "# all_means = {}\n",
    "# for column in categorical_features_target:\n",
    "   \n",
    "#    column_means = X_encoded_target.groupby(column)[column,'revenue'].mean().to_dict()['revenue']\n",
    "   \n",
    "#    X_encoded_target[column] = X_encoded_target.groupby(column)['revenue'].transform('mean')\n",
    "   \n",
    "#    all_means[column] = column_means\n",
    "   \n",
    "    \n",
    "# X_encoded_target.drop(columns=['revenue'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # label\n",
    "# label_encoder = LabelEncoder()\n",
    "\n",
    "# X_encoded_label = X.copy()\n",
    "\n",
    "# X_encoded_label[categorical_features] = X_encoded_label[categorical_features].apply(label_encoder.fit_transform)\n",
    "\n",
    "# log all the columns that are int or float\n",
    "\n",
    "\n",
    "# # target\n",
    "X_total = pd.concat([X, y], axis=1)\n",
    "\n",
    "X_encoded_target = X_total.copy()\n",
    "\n",
    "# remove revenue outliers that are more than 3 std away from mean in X_encoded_target\n",
    "\n",
    "X_encoded_target = X_encoded_target[np.abs(X_encoded_target.revenue - X_encoded_target.revenue.mean()) <= (3 * X_encoded_target.revenue.std())]\n",
    "\n",
    "all_means = {}\n",
    "\n",
    "for column in categorical_features:\n",
    "   \n",
    "   column_means = X_encoded_target.groupby(column)[column,'revenue'].mean().to_dict()['revenue']\n",
    "   \n",
    "   X_encoded_target[column] = X_encoded_target.groupby(column)['revenue'].transform('mean')\n",
    "   \n",
    "   all_means[column] = column_means\n",
    "\n",
    "y_target = X_encoded_target.revenue\n",
    "    \n",
    "X_encoded_target.drop(columns=['revenue'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 12\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "\n",
    "    param = {\n",
    "        'random_state': 48,\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 10),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n",
    "        #'n_estimators': trial.suggest_int('n_estimators', 10, 3000),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
    "        'subsample': trial.suggest_loguniform('subsample', 0.01, 1.0),\n",
    "        'colsample_bytree': trial.suggest_loguniform('colsample_bytree', 0.01, 1.0),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 1.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 1.0),\n",
    "        'eval_metric': 'rmse',\n",
    "\n",
    "    }\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    kf_scores = np.empty(5)\n",
    "    \n",
    "    model = xgb.XGBRegressor(**param)\n",
    "    \n",
    "    X_selected = X_encoded_one_hot\n",
    "    \n",
    "    for idx, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
    "        X_train, X_test = X_selected[train_index], X_selected[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "  \n",
    "        model.fit(X_train, y_train,eval_set=[(X_test,y_test)], early_stopping_rounds=100, verbose=False)\n",
    "    \n",
    "        preds = model.predict(X_test)\n",
    "        \n",
    "        y_test_exp = np.expm1(y_test)\n",
    "        preds_exp = np.expm1(preds)\n",
    "        \n",
    "        preds_exp = np.where(preds_exp < 0, 0, preds_exp)\n",
    "        \n",
    "        kf_scores[idx] = rmsle(y_test_exp, preds_exp)\n",
    "\n",
    "    return np.mean(kf_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=500)\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)\n",
    "print('Best value:', study.best_value)\n",
    "\n",
    "\n",
    "params = study.best_trial.params\n",
    "val = study.best_trial.value\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Target encoding\n",
    "\n",
    "# X_total = pd.concat([X, y], axis=1)\n",
    "\n",
    "# X_encoded_target = X_total.copy()\n",
    "\n",
    "\n",
    "# X_encoded_target = X_encoded_target[np.abs(X_encoded_target.revenue - X_encoded_target.revenue.mean()) <= (3 * X_encoded_target.revenue.std())]\n",
    "\n",
    "# all_means = {}\n",
    "\n",
    "# target_encode_features = ['mall_name', 'chain_name']\n",
    "\n",
    "# for column in target_encode_features:\n",
    "   \n",
    "#    column_means = X_encoded_target.groupby(column)[column,'revenue'].mean().to_dict()['revenue']\n",
    "   \n",
    "#    X_encoded_target[column] = X_encoded_target.groupby(column)['revenue'].transform('mean')\n",
    "#    X_encoded_target[column] = X_encoded_target[column].astype('float64')\n",
    "   \n",
    "#    all_means[column] = column_means\n",
    "\n",
    "# y_target = X_encoded_target.revenue\n",
    "    \n",
    "# X_encoded_target.drop(columns=['revenue'], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# categorical_features = categorical_features.drop(['mall_name', 'chain_name'])\n",
    "\n",
    "# full_pipeline = ColumnTransformer([('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features )], remainder='passthrough')\n",
    "# one_hot_encoder = full_pipeline.fit(X_encoded_target)\n",
    "# X_encoded_target_one_hot = one_hot_encoder.transform(X_encoded_target)\n",
    "\n",
    "\n",
    "# X_test_encoded_target = X_test.copy()\n",
    "\n",
    "# for column in categorical_features:\n",
    "#     X_test_encoded_target[column] = X_test_encoded_target[column].map(all_means[column])\n",
    "#     # convert to float\n",
    "#     X_test_encoded_target[column] = X_test_encoded_target[column].astype(float)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit ('3.10.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e748b08df6639b92156e1f0a2e584fc605f942beb5319c4ded409ee9197cfce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
