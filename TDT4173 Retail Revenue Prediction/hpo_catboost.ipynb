{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import *\n",
    "import lightgbm as lgbm\n",
    "import xgboost as xgb\n",
    "import catboost as cat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sqlalchemy import column\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#!pip install optuna \n",
    "import optuna\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_category(X):\n",
    "    for col in X.columns:\n",
    "        if ( (X[col].dtype != 'int64') and (X[col].dtype != 'float64') and (X[col].dtype != 'bool')):\n",
    "            X[col] = X[col].astype('category')\n",
    "            \n",
    "    return X\n",
    "\n",
    "def remove_outliers(df, column_names, n):\n",
    "    for column_name in column_names:\n",
    "        mean = df[column_name].mean()\n",
    "        std = df[column_name].std()\n",
    "        df = df[(df[column_name] > mean - n*std) & (df[column_name] < mean + n*std)]\n",
    "    return df\n",
    "    \n",
    "def log_func(y, shift_var):\n",
    "    return np.log(y+shift_var)\n",
    "\n",
    "def exp_func(y, shift_var):\n",
    "    return np.exp(y)-shift_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def rmsle(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes the Root Mean Squared Logarithmic Error \n",
    "    \n",
    "    Args:\n",
    "        y_true (np.array): n-dimensional vector of ground-truth values \n",
    "        y_pred (np.array): n-dimensional vecotr of predicted values \n",
    "    \n",
    "    Returns:\n",
    "        A scalar float with the rmsle value \n",
    "    \n",
    "    Note: You can alternatively use sklearn and just do: \n",
    "        `sklearn.metrics.mean_squared_log_error(y_true, y_pred) ** 0.5`\n",
    "    \"\"\"\n",
    "    assert (y_true >= 0).all(), 'Received negative y_true values'\n",
    "    assert (y_pred >= 0).all(), 'Received negative y_pred values'\n",
    "    assert y_true.shape == y_pred.shape, 'y_true and y_pred have different shapes'\n",
    "    y_true_log1p = np.log1p(y_true)  # log(1 + y_true)\n",
    "    y_pred_log1p = np.log1p(y_pred)  # log(1 + y_pred)\n",
    "    return np.sqrt(np.mean(np.square(y_pred_log1p - y_true_log1p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_train = pd.read_csv('data/stores_train_with_extra_features.csv')\n",
    "stores_test = pd.read_csv('data/stores_test_with_extra_features.csv')\n",
    "\n",
    "plaace_hierarchy = pd.read_csv('data/plaace_hierarchy.csv')\n",
    "grunnkrets = pd.read_csv('data/grunnkrets_norway_stripped.csv')\n",
    "grunnkrets_ages = pd.read_csv('data/grunnkrets_age_distribution.csv')\n",
    "grunnkrets_household_types = pd.read_csv('data/grunnkrets_households_num_persons.csv')\n",
    "grunnkrets_household_income = pd.read_csv('data/grunnkrets_income_households.csv')\n",
    "\n",
    "stores_train_copy= stores_train.copy()\n",
    "\n",
    "plaace_hierarchy_copy = plaace_hierarchy.copy()\n",
    "plaace_hierarchy_copy.drop(columns='sales_channel_name', inplace=True)\n",
    "plaace_hierarchy_copy['lv1'] = plaace_hierarchy_copy['lv1'].astype('category')\n",
    "plaace_hierarchy_copy['lv2'] = plaace_hierarchy_copy['lv2'].astype('category')\n",
    "\n",
    "\n",
    "grunnkrets_copy = grunnkrets.copy()\n",
    "grunnkrets_copy.rename(columns={'year': 'year_1'}, inplace=True)\n",
    "\n",
    "grunnkrets_ages_copy = grunnkrets_ages.copy()\n",
    "grunnkrets_ages_copy.rename(columns={'year': 'year_2'}, inplace=True)\n",
    "grunnkrets_ages_copy['grunnkrets_population'] = grunnkrets_ages_copy.iloc[:, 2:].sum(axis=1)\n",
    "\n",
    "grunnkrets_household_types_copy = grunnkrets_household_types.copy()\n",
    "grunnkrets_household_types_copy.rename(columns={'year': 'year_3'}, inplace=True)\n",
    "grunnkrets_household_types_copy[grunnkrets_household_types_copy.columns[2:]] = grunnkrets_household_types_copy[grunnkrets_household_types_copy.columns[2:]].astype('int64')\n",
    "\n",
    "grunnkrets_household_income_copy = grunnkrets_household_income.copy()\n",
    "grunnkrets_household_income_copy.rename(columns={'year': 'year_4', 'singles': 'singles_income','couple_without_children':'couple_without_children_income'}, inplace=True)\n",
    "grunnkrets_household_income_copy.rename(columns={'singles': 'singles_income', }, inplace=True)\n",
    "\n",
    "#set the values that are 0 to the lowest value in the column\n",
    "# for column in grunnkrets_household_income_copy.columns[2:]:\n",
    "#     grunnkrets_household_income_copy[column] = grunnkrets_household_income_copy[column].apply(lambda x: grunnkrets_household_income_copy[column].min() if x == 0 else x)\n",
    "    \n",
    "\n",
    "df = stores_train_copy\n",
    "\n",
    "df = pd.merge(df, plaace_hierarchy_copy, on='plaace_hierarchy_id', how='left')\n",
    "df = pd.merge(df, grunnkrets_copy, on='grunnkrets_id', how='left')\n",
    "df = pd.merge(df, grunnkrets_ages_copy, on='grunnkrets_id', how='left')\n",
    "df = pd.merge(df, grunnkrets_household_types_copy, on='grunnkrets_id', how='left')\n",
    "df = pd.merge(df, grunnkrets_household_income_copy, on='grunnkrets_id', how='left')\n",
    "\n",
    "\n",
    "\n",
    "df['grunnkrets_population_density'] = df['grunnkrets_population'] / df['area_km2']\n",
    "\n",
    "\n",
    "\n",
    "df.drop_duplicates(subset=['store_id'], keep='first', inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "columns_to_drop = ['revenue',\n",
    "                  'store_id',\n",
    "                  'plaace_hierarchy_id',\n",
    "                  'grunnkrets_id',\n",
    "                  'year',\n",
    "                   'address',\n",
    "                  'store_name',\n",
    "                  \n",
    "                  'year_1',\n",
    "                  'geometry',\n",
    "                  \n",
    "                  #'area_km2',\n",
    "               \n",
    "                  'grunnkrets_name',\n",
    "                  'district_name',\n",
    "             \n",
    "                  'municipality_name',\n",
    "                  \n",
    "                  \n",
    "                  'year_2',\n",
    "                  'year_3',\n",
    "                  'year_4',\n",
    "                 \n",
    "                \n",
    "                  'sales_channel_name',\n",
    "                   #'mall_name',\n",
    "                  #'chain_name',\n",
    "                  \n",
    "                  \n",
    "                  \n",
    "                     'lv1',\n",
    "                  'lv2',\n",
    "                  'lv3',\n",
    "                  'lv4',\n",
    "                  \n",
    "                  # 'lv1_desc',\n",
    "                  # 'lv2_desc',\n",
    "                  # 'lv3_desc',\n",
    "                  # 'lv4_desc'\n",
    "                \n",
    "#                 'closest_busstop',\n",
    "                  \n",
    "#     'num_closest_busstops_250m',\n",
    "#    'num_closest_busstops_500m',\n",
    "\n",
    "#        'num_closest_busstops_1000m', 'num_closest_busstops_2500m',\n",
    "#        'num_closest_busstops_5000m', \n",
    "#        'num_closest_busstops',\n",
    "#        'num_closest_busstops_10000m', 'num_closest_busstops_15000m',\n",
    "       \n",
    "#        'closest_store_lv1', 'closest_store_lv2',\n",
    "#        'closest_store_lv3', 'closest_store_lv4', \n",
    "       \n",
    "#        'num_closest_stores_lv1_250m',   \n",
    "#    'num_closest_stores_lv1_500m', \n",
    "   \n",
    "#    'num_closest_stores_lv1_1000m',\n",
    "    \n",
    "#     'num_closest_stores_lv1_2500m',\n",
    "#        'num_closest_stores_lv1_5000m', \n",
    "#        'num_closest_stores_lv1',\n",
    "#        'num_closest_stores_lv1_10000m', \n",
    "# 'num_closest_stores_lv1_15000m',\n",
    "       \n",
    "#        'num_closest_stores_lv2_250m', \n",
    "   \n",
    "   \n",
    "#    'num_closest_stores_lv2_500m',\n",
    "   \n",
    "#     'num_closest_stores_lv2_1000m', \n",
    "    \n",
    "#     'num_closest_stores_lv2_2500m',\n",
    "#        'num_closest_stores_lv2_5000m',\n",
    "#        'num_closest_stores_lv2',\n",
    "#        'num_closest_stores_lv2_10000m', 'num_closest_stores_lv2_15000m',\n",
    "       \n",
    "#         'num_closest_stores_lv3_250m', \n",
    "   \n",
    "   \n",
    "#    'num_closest_stores_lv3_500m',\n",
    "   \n",
    "#        'num_closest_stores_lv3_1000m', 'num_closest_stores_lv3_2500m',\n",
    "#        'num_closest_stores_lv3_5000m', \n",
    "#        'num_closest_stores_lv3',\n",
    "#        'num_closest_stores_lv3_10000m', 'num_closest_stores_lv3_15000m',\n",
    "       \n",
    "#         'num_closest_stores_lv4_250m', \n",
    "   \n",
    "#    'num_closest_stores_lv4_500m',\n",
    "   \n",
    "#        'num_closest_stores_lv4_1000m', 'num_closest_stores_lv4_2500m',\n",
    "#        'num_closest_stores_lv4_5000m', \n",
    "#        'num_closest_stores_lv4',\n",
    "#        'num_closest_stores_lv4_10000m', 'num_closest_stores_lv4_15000m',\n",
    "#                   'distance_to_oslo',\n",
    "                  'distance_to_bergen',\n",
    "                  'distance_to_trondheim',\n",
    "                  'distance_to_stavanger',\n",
    "                  'distance_to_drammen',\n",
    "                  # 'grunnkrets_population',\n",
    "                  # 'grunnkrets_population_density',\n",
    "                  \n",
    "                  # 'num_closest_busstops_100m',\n",
    "                  # 'num_closest_busstops_750m',\n",
    "                  # 'num_closest_stores_lv1_100m',\n",
    "                  # 'num_closest_stores_lv1_750m', \n",
    "                  # 'num_closest_stores_lv2_100m',\n",
    "                  # 'num_closest_stores_lv2_750m',\n",
    "                  # 'num_closest_stores_lv3_100m',\n",
    "                  # 'num_closest_stores_lv3_750m',\n",
    "              \n",
    "                  # 'num_closest_stores_lv4_750m',\n",
    "                  \n",
    "                  ]\n",
    "\n",
    "\n",
    "# fill in missing values of float columns with mean\n",
    "\n",
    "\n",
    "X = df.drop(columns=columns_to_drop)\n",
    "X = convert_to_category(X)\n",
    "\n",
    "# for column in numerical_columns:\n",
    "#    X[column] = np.log(X[column]+0.001)\n",
    "\n",
    "\n",
    "y = df.revenue\n",
    "y = np.log1p(y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "categorical_features = X.select_dtypes(include=['category']).columns\n",
    "numerical_columns = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "\n",
    "# One hot encoding\n",
    "        \n",
    "full_pipeline = ColumnTransformer([('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)], remainder='passthrough')\n",
    "one_hot_encoder = full_pipeline.fit(X)\n",
    "X_encoded_one_hot = one_hot_encoder.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 12\n",
    "X_selected = X_encoded_one_hot.copy()\n",
    "\n",
    "def objective(trial,data=X_encoded_one_hot,target=y):\n",
    " \n",
    "    param = {}\n",
    "    param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.001, 0.1, 0.001)\n",
    "    param['depth'] = trial.suggest_int('depth', 2, 10)\n",
    "    param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 0.0, 5.5, 0.5)\n",
    "    param['min_child_samples'] = trial.suggest_categorical('min_child_samples', [1, 4, 8, 16, 32])\n",
    "    #param['grow_policy'] = 'Depthwise'\n",
    "    param['iterations'] = trial.suggest_int('iterations', 10, 2000)\n",
    "    param['eval_metric'] = 'RMSE'\n",
    "    #param['od_type'] = 'iter'\n",
    "    # param['od_wait'] = 20\n",
    "    # param['random_state'] = 42\n",
    "    # param['logging_level'] = 'Silent'\n",
    "    param['task_type'] = 'GPU'\n",
    "    \n",
    "    param = {\n",
    "        'random_state': random_state,\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 10),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n",
    "        'subsample': trial.suggest_loguniform('subsample', 0.01, 1.0),\n",
    "        'min_child_samples': trial.suggest_int('min_child_smaples', 1, 100),\n",
    "        'l2_leaf_reg': trial.suggest_discrete_uniform('l2_leaf_reg', 0.0, 5.5, 0.5),\n",
    "        #'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 50.0),\n",
    "        'eval_metric': 'RMSE',\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    model = cat.CatBoostRegressor(**param)\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    kf_scores = np.empty(5)\n",
    "    \n",
    "    X_selected = X_encoded_one_hot\n",
    "    \n",
    "    for idx, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
    "        X_train, X_test = X_selected[train_index], X_selected[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "  \n",
    "        model.fit(X_train, y_train,eval_set=[(X_test,y_test)], early_stopping_rounds=100, verbose=False)\n",
    "    \n",
    "        preds = model.predict(X_test)\n",
    "        \n",
    "        y_test_exp = np.expm1(y_test)\n",
    "        preds_exp = np.expm1(preds)\n",
    "        \n",
    "        preds_exp = np.where(preds_exp < 0, 0, preds_exp)\n",
    "        \n",
    "        kf_scores[idx] = rmsle(y_test_exp, preds_exp)\n",
    "\n",
    "    return np.mean(kf_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-10 08:17:21,543]\u001b[0m A new study created in memory with name: no-name-a329b94b-9d4a-4acc-b761-dfff8c7bcecc\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 08:19:35,929]\u001b[0m Trial 0 finished with value: 0.7286276430070402 and parameters: {'learning_rate': 0.065, 'depth': 4, 'l2_leaf_reg': 3.0, 'min_child_samples': 4, 'iterations': 1219}. Best is trial 0 with value: 0.7286276430070402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 08:19:59,401]\u001b[0m Trial 1 finished with value: 0.7473130476413375 and parameters: {'learning_rate': 0.04, 'depth': 10, 'l2_leaf_reg': 5.0, 'min_child_samples': 16, 'iterations': 129}. Best is trial 0 with value: 0.7286276430070402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 08:22:12,884]\u001b[0m Trial 2 finished with value: 0.7336784930686423 and parameters: {'learning_rate': 0.051000000000000004, 'depth': 3, 'l2_leaf_reg': 2.5, 'min_child_samples': 4, 'iterations': 1178}. Best is trial 0 with value: 0.7286276430070402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 08:35:38,013]\u001b[0m Trial 3 finished with value: 0.7286330838907938 and parameters: {'learning_rate': 0.021, 'depth': 10, 'l2_leaf_reg': 0.0, 'min_child_samples': 1, 'iterations': 1781}. Best is trial 0 with value: 0.7286276430070402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 08:38:11,346]\u001b[0m Trial 4 finished with value: 0.7345619069480447 and parameters: {'learning_rate': 0.041, 'depth': 4, 'l2_leaf_reg': 0.5, 'min_child_samples': 16, 'iterations': 878}. Best is trial 0 with value: 0.7286276430070402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 08:38:25,310]\u001b[0m Trial 5 finished with value: 0.7512328477103629 and parameters: {'learning_rate': 0.05, 'depth': 5, 'l2_leaf_reg': 1.5, 'min_child_samples': 4, 'iterations': 139}. Best is trial 0 with value: 0.7286276430070402.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 08:41:12,692]\u001b[0m Trial 6 finished with value: 0.7282144692607909 and parameters: {'learning_rate': 0.095, 'depth': 3, 'l2_leaf_reg': 3.0, 'min_child_samples': 4, 'iterations': 1861}. Best is trial 6 with value: 0.7282144692607909.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 08:43:47,645]\u001b[0m Trial 7 finished with value: 0.7287823606490338 and parameters: {'learning_rate': 0.064, 'depth': 5, 'l2_leaf_reg': 1.5, 'min_child_samples': 4, 'iterations': 862}. Best is trial 6 with value: 0.7282144692607909.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 08:44:24,325]\u001b[0m Trial 8 finished with value: 0.7454962795367038 and parameters: {'learning_rate': 0.083, 'depth': 2, 'l2_leaf_reg': 1.0, 'min_child_samples': 32, 'iterations': 371}. Best is trial 6 with value: 0.7282144692607909.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 08:47:32,255]\u001b[0m Trial 9 finished with value: 0.7256562700196951 and parameters: {'learning_rate': 0.098, 'depth': 8, 'l2_leaf_reg': 3.0, 'min_child_samples': 4, 'iterations': 1909}. Best is trial 9 with value: 0.7256562700196951.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 08:54:37,597]\u001b[0m Trial 10 finished with value: 0.7342641142048398 and parameters: {'learning_rate': 0.008, 'depth': 8, 'l2_leaf_reg': 4.5, 'min_child_samples': 8, 'iterations': 1540}. Best is trial 9 with value: 0.7256562700196951.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 08:57:32,332]\u001b[0m Trial 11 finished with value: 0.7257232409218256 and parameters: {'learning_rate': 0.1, 'depth': 7, 'l2_leaf_reg': 3.5, 'min_child_samples': 4, 'iterations': 1978}. Best is trial 9 with value: 0.7256562700196951.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 09:00:09,891]\u001b[0m Trial 12 finished with value: 0.7265452874197336 and parameters: {'learning_rate': 0.1, 'depth': 7, 'l2_leaf_reg': 4.0, 'min_child_samples': 32, 'iterations': 1939}. Best is trial 9 with value: 0.7256562700196951.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 09:02:58,045]\u001b[0m Trial 13 finished with value: 0.7258903623146822 and parameters: {'learning_rate': 0.081, 'depth': 8, 'l2_leaf_reg': 3.5, 'min_child_samples': 8, 'iterations': 1534}. Best is trial 9 with value: 0.7256562700196951.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 09:05:42,068]\u001b[0m Trial 14 finished with value: 0.7251523008525913 and parameters: {'learning_rate': 0.083, 'depth': 7, 'l2_leaf_reg': 5.5, 'min_child_samples': 1, 'iterations': 1568}. Best is trial 14 with value: 0.7251523008525913.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 09:10:43,951]\u001b[0m Trial 15 finished with value: 0.7241650859126689 and parameters: {'learning_rate': 0.083, 'depth': 9, 'l2_leaf_reg': 5.5, 'min_child_samples': 1, 'iterations': 1542}. Best is trial 15 with value: 0.7241650859126689.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 09:15:24,861]\u001b[0m Trial 16 finished with value: 0.723399359064399 and parameters: {'learning_rate': 0.077, 'depth': 9, 'l2_leaf_reg': 5.5, 'min_child_samples': 1, 'iterations': 1529}. Best is trial 16 with value: 0.723399359064399.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 09:19:37,802]\u001b[0m Trial 17 finished with value: 0.7245839738775315 and parameters: {'learning_rate': 0.067, 'depth': 9, 'l2_leaf_reg': 5.5, 'min_child_samples': 1, 'iterations': 1282}. Best is trial 16 with value: 0.723399359064399.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 09:23:15,796]\u001b[0m Trial 18 finished with value: 0.7244662918070819 and parameters: {'learning_rate': 0.07300000000000001, 'depth': 9, 'l2_leaf_reg': 4.5, 'min_child_samples': 1, 'iterations': 659}. Best is trial 16 with value: 0.723399359064399.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 09:29:22,269]\u001b[0m Trial 19 finished with value: 0.7244638898416267 and parameters: {'learning_rate': 0.054, 'depth': 9, 'l2_leaf_reg': 5.0, 'min_child_samples': 1, 'iterations': 1412}. Best is trial 16 with value: 0.723399359064399.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 09:31:48,037]\u001b[0m Trial 20 finished with value: 0.7254380200445366 and parameters: {'learning_rate': 0.08700000000000001, 'depth': 6, 'l2_leaf_reg': 5.5, 'min_child_samples': 1, 'iterations': 1646}. Best is trial 16 with value: 0.723399359064399.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 09:36:47,282]\u001b[0m Trial 21 finished with value: 0.725120825703101 and parameters: {'learning_rate': 0.055, 'depth': 9, 'l2_leaf_reg': 5.0, 'min_child_samples': 1, 'iterations': 1343}. Best is trial 16 with value: 0.723399359064399.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 09:42:55,728]\u001b[0m Trial 22 finished with value: 0.7239943854516144 and parameters: {'learning_rate': 0.074, 'depth': 10, 'l2_leaf_reg': 4.5, 'min_child_samples': 1, 'iterations': 1405}. Best is trial 16 with value: 0.723399359064399.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 09:49:01,087]\u001b[0m Trial 23 finished with value: 0.7239943854516144 and parameters: {'learning_rate': 0.074, 'depth': 10, 'l2_leaf_reg': 4.5, 'min_child_samples': 1, 'iterations': 1008}. Best is trial 16 with value: 0.723399359064399.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 09:54:33,151]\u001b[0m Trial 24 finished with value: 0.7252155981331151 and parameters: {'learning_rate': 0.075, 'depth': 10, 'l2_leaf_reg': 4.0, 'min_child_samples': 1, 'iterations': 1004}. Best is trial 16 with value: 0.723399359064399.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 10:01:07,631]\u001b[0m Trial 25 finished with value: 0.7233249368169281 and parameters: {'learning_rate': 0.07300000000000001, 'depth': 10, 'l2_leaf_reg': 4.5, 'min_child_samples': 1, 'iterations': 1113}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 10:06:51,564]\u001b[0m Trial 26 finished with value: 0.7250410941681408 and parameters: {'learning_rate': 0.089, 'depth': 10, 'l2_leaf_reg': 4.0, 'min_child_samples': 8, 'iterations': 629}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 10:10:22,701]\u001b[0m Trial 27 finished with value: 0.7252738921051657 and parameters: {'learning_rate': 0.061, 'depth': 8, 'l2_leaf_reg': 5.0, 'min_child_samples': 16, 'iterations': 1004}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 10:19:40,034]\u001b[0m Trial 28 finished with value: 0.7246020950751868 and parameters: {'learning_rate': 0.039, 'depth': 10, 'l2_leaf_reg': 4.5, 'min_child_samples': 1, 'iterations': 1095}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 10:23:10,998]\u001b[0m Trial 29 finished with value: 0.7251520445792486 and parameters: {'learning_rate': 0.07, 'depth': 9, 'l2_leaf_reg': 2.5, 'min_child_samples': 32, 'iterations': 627}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 10:25:24,410]\u001b[0m Trial 30 finished with value: 0.7274411349291127 and parameters: {'learning_rate': 0.060000000000000005, 'depth': 6, 'l2_leaf_reg': 3.5, 'min_child_samples': 1, 'iterations': 833}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 10:35:25,445]\u001b[0m Trial 31 finished with value: 0.7240459016463827 and parameters: {'learning_rate': 0.078, 'depth': 10, 'l2_leaf_reg': 4.5, 'min_child_samples': 1, 'iterations': 1123}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 10:40:58,750]\u001b[0m Trial 32 finished with value: 0.724092648710847 and parameters: {'learning_rate': 0.091, 'depth': 10, 'l2_leaf_reg': 5.0, 'min_child_samples': 1, 'iterations': 1337}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 10:47:15,411]\u001b[0m Trial 33 finished with value: 0.7246734279709113 and parameters: {'learning_rate': 0.07200000000000001, 'depth': 10, 'l2_leaf_reg': 4.0, 'min_child_samples': 1, 'iterations': 1737}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 10:51:53,978]\u001b[0m Trial 34 finished with value: 0.7254605839033931 and parameters: {'learning_rate': 0.066, 'depth': 9, 'l2_leaf_reg': 5.0, 'min_child_samples': 16, 'iterations': 1204}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 11:00:11,220]\u001b[0m Trial 35 finished with value: 0.7239943854516144 and parameters: {'learning_rate': 0.074, 'depth': 10, 'l2_leaf_reg': 4.5, 'min_child_samples': 1, 'iterations': 1441}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 11:03:44,720]\u001b[0m Trial 36 finished with value: 0.7264463109403462 and parameters: {'learning_rate': 0.046, 'depth': 8, 'l2_leaf_reg': 5.5, 'min_child_samples': 1, 'iterations': 748}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 11:11:26,436]\u001b[0m Trial 37 finished with value: 0.7274112992165892 and parameters: {'learning_rate': 0.026000000000000002, 'depth': 9, 'l2_leaf_reg': 2.0, 'min_child_samples': 1, 'iterations': 1076}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 11:20:00,873]\u001b[0m Trial 38 finished with value: 0.7247455447854207 and parameters: {'learning_rate': 0.059000000000000004, 'depth': 10, 'l2_leaf_reg': 3.5, 'min_child_samples': 16, 'iterations': 1218}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 11:25:56,638]\u001b[0m Trial 39 finished with value: 0.7240015575120067 and parameters: {'learning_rate': 0.094, 'depth': 10, 'l2_leaf_reg': 4.0, 'min_child_samples': 32, 'iterations': 1755}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 11:26:12,552]\u001b[0m Trial 40 finished with value: 0.7352601916112785 and parameters: {'learning_rate': 0.078, 'depth': 4, 'l2_leaf_reg': 5.0, 'min_child_samples': 1, 'iterations': 410}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 11:31:34,386]\u001b[0m Trial 41 finished with value: 0.7246968351126738 and parameters: {'learning_rate': 0.07, 'depth': 10, 'l2_leaf_reg': 4.5, 'min_child_samples': 1, 'iterations': 1415}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 11:36:33,588]\u001b[0m Trial 42 finished with value: 0.7244302282677799 and parameters: {'learning_rate': 0.077, 'depth': 10, 'l2_leaf_reg': 4.5, 'min_child_samples': 1, 'iterations': 1421}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 11:39:25,213]\u001b[0m Trial 43 finished with value: 0.7250032075973647 and parameters: {'learning_rate': 0.08600000000000001, 'depth': 9, 'l2_leaf_reg': 4.5, 'min_child_samples': 1, 'iterations': 1648}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 11:43:09,128]\u001b[0m Trial 44 finished with value: 0.7285739547720149 and parameters: {'learning_rate': 0.067, 'depth': 10, 'l2_leaf_reg': 0.0, 'min_child_samples': 8, 'iterations': 931}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 11:44:27,750]\u001b[0m Trial 45 finished with value: 0.7353362428453666 and parameters: {'learning_rate': 0.064, 'depth': 2, 'l2_leaf_reg': 3.0, 'min_child_samples': 1, 'iterations': 1285}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 11:45:57,652]\u001b[0m Trial 46 finished with value: 0.7258726063936984 and parameters: {'learning_rate': 0.081, 'depth': 5, 'l2_leaf_reg': 4.0, 'min_child_samples': 4, 'iterations': 1639}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 11:50:15,078]\u001b[0m Trial 47 finished with value: 0.7492896672028401 and parameters: {'learning_rate': 0.003, 'depth': 8, 'l2_leaf_reg': 3.5, 'min_child_samples': 1, 'iterations': 1440}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 11:53:08,055]\u001b[0m Trial 48 finished with value: 0.7245282350176566 and parameters: {'learning_rate': 0.093, 'depth': 9, 'l2_leaf_reg': 5.5, 'min_child_samples': 32, 'iterations': 1832}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 12:00:05,362]\u001b[0m Trial 49 finished with value: 0.7238749577172139 and parameters: {'learning_rate': 0.048, 'depth': 10, 'l2_leaf_reg': 5.0, 'min_child_samples': 1, 'iterations': 1496}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 12:02:42,347]\u001b[0m Trial 50 finished with value: 0.725447226592683 and parameters: {'learning_rate': 0.044000000000000004, 'depth': 7, 'l2_leaf_reg': 5.5, 'min_child_samples': 4, 'iterations': 1486}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 12:12:25,488]\u001b[0m Trial 51 finished with value: 0.7249362807536148 and parameters: {'learning_rate': 0.028, 'depth': 10, 'l2_leaf_reg': 5.0, 'min_child_samples': 1, 'iterations': 1297}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 12:23:25,744]\u001b[0m Trial 52 finished with value: 0.7237572745031919 and parameters: {'learning_rate': 0.033, 'depth': 10, 'l2_leaf_reg': 4.5, 'min_child_samples': 1, 'iterations': 1589}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 12:30:34,247]\u001b[0m Trial 53 finished with value: 0.724600448734064 and parameters: {'learning_rate': 0.038, 'depth': 9, 'l2_leaf_reg': 5.0, 'min_child_samples': 1, 'iterations': 1605}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 12:40:03,767]\u001b[0m Trial 54 finished with value: 0.7263289408822099 and parameters: {'learning_rate': 0.017, 'depth': 9, 'l2_leaf_reg': 4.5, 'min_child_samples': 1, 'iterations': 1719}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 12:51:55,288]\u001b[0m Trial 55 finished with value: 0.7237313243087378 and parameters: {'learning_rate': 0.034, 'depth': 10, 'l2_leaf_reg': 5.0, 'min_child_samples': 8, 'iterations': 1517}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:05:22,224]\u001b[0m Trial 56 finished with value: 0.724209964139252 and parameters: {'learning_rate': 0.029, 'depth': 10, 'l2_leaf_reg': 5.5, 'min_child_samples': 8, 'iterations': 1495}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:11:57,123]\u001b[0m Trial 57 finished with value: 0.7245413910523142 and parameters: {'learning_rate': 0.036000000000000004, 'depth': 9, 'l2_leaf_reg': 5.0, 'min_child_samples': 8, 'iterations': 1853}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:13:44,194]\u001b[0m Trial 58 finished with value: 0.7315613123071166 and parameters: {'learning_rate': 0.053000000000000005, 'depth': 3, 'l2_leaf_reg': 1.0, 'min_child_samples': 8, 'iterations': 1539}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:18:14,985]\u001b[0m Trial 59 finished with value: 0.7251188828232988 and parameters: {'learning_rate': 0.033, 'depth': 8, 'l2_leaf_reg': 5.5, 'min_child_samples': 8, 'iterations': 1692}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:27:12,480]\u001b[0m Trial 60 finished with value: 0.7257384203068662 and parameters: {'learning_rate': 0.018000000000000002, 'depth': 9, 'l2_leaf_reg': 5.0, 'min_child_samples': 16, 'iterations': 1802}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n",
      "\u001b[32m[I 2022-11-10 13:35:27,686]\u001b[0m Trial 61 finished with value: 0.7244955345326579 and parameters: {'learning_rate': 0.049, 'depth': 10, 'l2_leaf_reg': 4.0, 'min_child_samples': 1, 'iterations': 1477}. Best is trial 25 with value: 0.7233249368169281.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mNumber of finished trials:\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mlen\u001b[39m(study\u001b[39m.\u001b[39mtrials))\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBest trial:\u001b[39m\u001b[39m'\u001b[39m, study\u001b[39m.\u001b[39mbest_trial\u001b[39m.\u001b[39mparams)\n",
      "File \u001b[1;32mc:\\Users\\levit\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages\\optuna\\study\\study.py:400\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[39mif\u001b[39;00m n_jobs \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    393\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    394\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`n_jobs` argument has been deprecated in v2.7.0. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    395\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis feature will be removed in v4.0.0. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    396\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSee https://github.com/optuna/optuna/releases/tag/v2.7.0.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    397\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    398\u001b[0m     )\n\u001b[1;32m--> 400\u001b[0m _optimize(\n\u001b[0;32m    401\u001b[0m     study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    402\u001b[0m     func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    403\u001b[0m     n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    404\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    405\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    406\u001b[0m     catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[0;32m    407\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    408\u001b[0m     gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    409\u001b[0m     show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    410\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\levit\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m show_progress_bar:\n",
      "File \u001b[1;32mc:\\Users\\levit\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\levit\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages\\optuna\\study\\_optimize.py:213\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    210\u001b[0m     thread\u001b[39m.\u001b[39mstart()\n\u001b[0;32m    212\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 213\u001b[0m     value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    214\u001b[0m \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn [11], line 47\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial, data, target)\u001b[0m\n\u001b[0;32m     44\u001b[0m X_train, X_test \u001b[39m=\u001b[39m X_selected[train_index], X_selected[test_index]\n\u001b[0;32m     45\u001b[0m y_train, y_test \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39miloc[train_index], y\u001b[39m.\u001b[39miloc[test_index]\n\u001b[1;32m---> 47\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train,eval_set\u001b[39m=\u001b[39;49m[(X_test,y_test)], early_stopping_rounds\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     49\u001b[0m preds \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m     51\u001b[0m y_test_exp \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexpm1(y_test)\n",
      "File \u001b[1;32mc:\\Users\\levit\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages\\catboost\\core.py:5730\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   5727\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m params:\n\u001b[0;32m   5728\u001b[0m     CatBoostRegressor\u001b[39m.\u001b[39m_check_is_compatible_loss(params[\u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m-> 5730\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, cat_features, text_features, embedding_features, \u001b[39mNone\u001b[39;49;00m, sample_weight, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, baseline,\n\u001b[0;32m   5731\u001b[0m                  use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description,\n\u001b[0;32m   5732\u001b[0m                  verbose_eval, metric_period, silent, early_stopping_rounds,\n\u001b[0;32m   5733\u001b[0m                  save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "File \u001b[1;32mc:\\Users\\levit\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages\\catboost\\core.py:2355\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2351\u001b[0m allow_clear_pool \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mallow_clear_pool\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   2353\u001b[0m \u001b[39mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[0;32m   2354\u001b[0m     plot_wrapper(plot, plot_file, \u001b[39m'\u001b[39m\u001b[39mTraining plots\u001b[39m\u001b[39m'\u001b[39m, [_get_train_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params())]):\n\u001b[1;32m-> 2355\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(\n\u001b[0;32m   2356\u001b[0m         train_pool,\n\u001b[0;32m   2357\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39meval_sets\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   2358\u001b[0m         params,\n\u001b[0;32m   2359\u001b[0m         allow_clear_pool,\n\u001b[0;32m   2360\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39minit_model\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[0;32m   2361\u001b[0m     )\n\u001b[0;32m   2363\u001b[0m \u001b[39m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[0;32m   2364\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object\u001b[39m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[1;32mc:\\Users\\levit\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages\\catboost\\core.py:1759\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1758\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train\u001b[39m(\u001b[39mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[1;32m-> 1759\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_object\u001b[39m.\u001b[39;49m_train(train_pool, test_pool, params, allow_clear_pool, init_model\u001b[39m.\u001b[39;49m_object \u001b[39mif\u001b[39;49;00m init_model \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m   1760\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[1;32m_catboost.pyx:4622\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:4671\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.07300000000000001,\n",
       " 'depth': 10,\n",
       " 'l2_leaf_reg': 4.5,\n",
       " 'min_child_samples': 1,\n",
       " 'iterations': 1113}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = study.best_trial.params\n",
    "val = study.best_trial.value\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "params = study.best_trial.params\n",
    "val = study.best_trial.value\n",
    "\n",
    "dict = {'val': val, 'params': params}\n",
    "\n",
    "# save the params and value\n",
    "\n",
    "with open('cat_params.json', 'w') as fp:\n",
    "    json.dump(dict, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit ('3.10.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e748b08df6639b92156e1f0a2e584fc605f942beb5319c4ded409ee9197cfce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
